import torch
import transformers
import re
import streamlit as st
import functools
import os
import multiprocessing
import warnings

torch.classes.__path__ = []

twitter_magic_number = 280

#os.environ["TOKENIZERS_PARALLELISM"] = "false"
warnings.filterwarnings("ignore")
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

st.set_page_config(
    page_title="Message to Emoji Translator",
    page_icon=":fast_forward:",
    layout="centered",
)

# st.markdown("""
#     <style>
#     .footer {
#         position: fixed;
#         bottom: 0;
#         left: 0;
#         width: 100%;
#         background-color: #FFF1;
#         text-align: center;
#         padding: 15px;
#         font-size: 15px;
#         color: #FFFFFF;
#     }
#     </style>
#     <div class="footer">
#         &copy; Nazmiev Airat 2025 👋
    
#     </div>
#     """, unsafe_allow_html=True
# )

st.markdown(
    """
    <style>
    textarea:disabled {
        opacity: 1 !important;                     
        color: #000000 !important;
        -webkit-text-fill-color: #FFFFFF !important;
        background-color: inherit !important;
        filter: none !important;
    }
    [data-testid="stTextArea"] label {
        opacity: 1 !important;
        color: #000000 !important;
        -webkit-text-fill-color: #FFFFFF !important;
    }
    .footer {
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        background-color: #FFF1;
        text-align: center;
        padding: 15px;
        font-size: 15px;
        color: #FFFFFF;
    }
    </style>
    <div class="footer">
        &copy; Nazmiev Airat 2025 👋
    
    </div>
    """,
    unsafe_allow_html=True,
)

st.title("Message 📝 to Emoji 😎 Translator")

available_languages = {
    "English 🦁" : ("en", "Enter the message to translate...", "English language"), 
    "Russian 🐻" : ("ru", "Введите сообщение для перевода...", "Русский язык"), 
    "Chinese 🐼" : ("zh", "输入要翻译的文本...", "中文")
}
language_abbr = {name : x[0] for name, x in available_languages.items()}
language_placeholder = {name : x[1] for name, x in available_languages.items()}
language_label = {name : x[2] for name, x in available_languages.items()}

language_option = st.selectbox(
    "Select language:",
    available_languages.keys(),
    index=0,
    placeholder="Select language...",
)

text_value = st.text_area(
    label=language_label[language_option],
    placeholder=language_placeholder[language_option],
    max_chars=twitter_magic_number,
    help=f"Let's speak the language of facts 😉. Facts are limited to {twitter_magic_number} chars (twit size)",
    height=150
)

def translate(text: str, model, tokenizer) -> str:
    input_tokens = tokenizer(text, return_tensors="pt")
    output_tokens = model.generate(**input_tokens)[0]
    return tokenizer.decode(output_tokens, skip_special_tokens=True)

### load translators:
@st.cache_resource
def load_ru_en_translator():
    ru_en_tokenizer = transformers.AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ru-en")
    ru_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-ru-en")

    ru_en_translator = functools.partial(translate, model=ru_en_model, tokenizer=ru_en_tokenizer)
    
    return ru_en_translator

@st.cache_resource
def load_zh_en_translator():
    zh_en_tokenizer = transformers.AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-zh-en", local_files_only=False)
    zh_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-zh-en", local_files_only=False)

    zh_en_translator = functools.partial(translate, model=zh_en_model, tokenizer=zh_en_tokenizer)
    
    return zh_en_translator

@st.cache_resource
def load_msg2emoji_translator():
    class Msg2EmojiTranslator:
        def __init__(
            self,
            tokenizer,
            generator,
            device: torch.device
        ) -> None:
            self.device = device
            self.tokenizer = tokenizer
            self.generator = generator.to(self.device)
            
        def translate(self, sentence: str | list[str], sep: str = '', **kwargs) -> torch.Tensor:
            decoded_emojis_list = []
            
            if isinstance(sentence, str):
                sentence = [sentence]

            for s in sentence:
                text_tokens = self.tokenizer(s, return_tensors="pt")
                generated_emoji_tokens = self.generator.generate(text_tokens["input_ids"].to(self.device), **kwargs)
                decoded_emojis = self.tokenizer.decode(generated_emoji_tokens[0].cpu(), skip_special_tokens=True).replace(" ", "")
                decoded_emojis_list.append(decoded_emojis)
                
            return sep.join(decoded_emojis_list)
    
    tokenizer = transformers.BartTokenizer.from_pretrained('AiratNazmiev/text2emoji-tokenizer')
    generator = transformers.BartForConditionalGeneration.from_pretrained('AiratNazmiev/text2emoji-bart-base')
    
    msg2emoji_translator = Msg2EmojiTranslator(
        tokenizer=tokenizer,
        generator=generator,
        device=device
    )
    
    return msg2emoji_translator

def text_preprocessing(text: str, ru_en_translator, zh_en_translator, language: str = 'en') -> str:
    if language == 'ru':
        text = ru_en_translator(text)
    elif language == 'zh':
        text = zh_en_translator(text)
    
    if len(text) > twitter_magic_number:
        print(f"It's twit translator. The max length of the input is {twitter_magic_number} characters")
        
    text_re = re.split(r"(?<=[.|!|?|\.\.\.])\s+", text.strip())
    
    return text_re


ru_en_translator = load_ru_en_translator()
zh_en_translator = load_zh_en_translator()
msg2emoji_translator = load_msg2emoji_translator()

st.text(ru_en_translator('Привет!'))

language_option = st.selectbox(
        "Select language:",
        ("английский язык. и точка", "русский язык", "китайский язык"),
        index=0,
        placeholder="Select language...",
    )
st.text(ru_en_translator(language_option))
st.text(zh_en_translator(language_option))

st.text(msg2emoji_translator.translate(
    ru_en_translator(text_preprocessing(language_option, ru_en_translator, zh_en_translator, 'ru')),
    sep='',
    num_beams=5, 
    do_sample=True, 
    max_length=20
))
