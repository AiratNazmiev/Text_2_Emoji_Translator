import torch
import transformers
import re
import streamlit as st
import functools
import os
import multiprocessing
import warnings

torch.classes.__path__ = []

twitter_magic_number = 280

#os.environ["TOKENIZERS_PARALLELISM"] = "false"
warnings.filterwarnings("ignore")
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

st.set_page_config(
    page_title="Message to Emoji Translator",
    page_icon=":fast_forward:",
    layout="centered",
)
st.title("Message üìù to Emoji üòé Translator")

st.markdown("""
    <style>
    .footer {
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        background-color: #FFF1;
        text-align: center;
        padding: 15px;
        font-size: 15px;
        color: #FFFFFF;
    }
    </style>
    <div class="footer">
        &copy; Nazmiev Airat 2025 üëã
    
    </div>
    """, unsafe_allow_html=True
)

st.markdown(
    """
    <style>
    textarea:disabled {
        opacity: 1 !important;                     
        color: #000000 !important;
        -webkit-text-fill-color: #FFFFFF !important;
        background-color: inherit !important;
        filter: none !important;
    }
    [data-testid="stTextArea"] label {
        opacity: 1 !important;
        color: #000000 !important;
        -webkit-text-fill-color: #FFFFFF !important;
    }
    """,
    unsafe_allow_html=True,
)

available_languages = {
    "English ü¶Å" : ("en", "Enter the message to translate...", "English language"), 
    "Russian üêª" : ("ru", "–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞...", "–†—É—Å—Å–∫–∏–π —è–∑—ã–∫"), 
    "Chinese üêº" : ("zh", "ËæìÂÖ•Ë¶ÅÁøªËØëÁöÑÊñáÊú¨...", "‰∏≠Êñá")
}
language_abbr = {name : x[0] for name, x in available_languages.items()}
language_placeholder = {name : x[1] for name, x in available_languages.items()}
language_label = {name : x[2] for name, x in available_languages.items()}

def translate(text: str, model, tokenizer) -> str:
    input_tokens = tokenizer(text, return_tensors="pt")
    output_tokens = model.generate(**input_tokens)[0]
    return tokenizer.decode(output_tokens, skip_special_tokens=True)

### load translators:
@st.cache_resource
def load_ru_en_translator():
    ru_en_tokenizer = transformers.AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ru-en")
    ru_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-ru-en")

    ru_en_translator = functools.partial(translate, model=ru_en_model, tokenizer=ru_en_tokenizer)
    
    return ru_en_translator

@st.cache_resource
def load_zh_en_translator():
    zh_en_tokenizer = transformers.AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-zh-en", local_files_only=False)
    zh_en_model = transformers.AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-zh-en", local_files_only=False)

    zh_en_translator = functools.partial(translate, model=zh_en_model, tokenizer=zh_en_tokenizer)
    
    return zh_en_translator

@st.cache_resource
def load_msg2emoji_translator():
    class Msg2EmojiTranslator:
        def __init__(
            self,
            tokenizer,
            generator,
            device: torch.device
        ) -> None:
            self.device = device
            self.tokenizer = tokenizer
            self.generator = generator.to(self.device)
            
        def translate(self, sentence: str | list[str], sep: str = '', **kwargs) -> torch.Tensor:
            decoded_emojis_list = []
            
            if isinstance(sentence, str):
                sentence = [sentence]

            for s in sentence:
                text_tokens = self.tokenizer(s, return_tensors="pt")
                generated_emoji_tokens = self.generator.generate(text_tokens["input_ids"].to(self.device), **kwargs)
                decoded_emojis = self.tokenizer.decode(generated_emoji_tokens[0].cpu(), skip_special_tokens=True).replace(" ", "")
                decoded_emojis_list.append(decoded_emojis)
                
            return sep.join(decoded_emojis_list)
    
    tokenizer = transformers.BartTokenizer.from_pretrained('AiratNazmiev/text2emoji-tokenizer')
    generator = transformers.BartForConditionalGeneration.from_pretrained('AiratNazmiev/text2emoji-bart-base')
    
    msg2emoji_translator = Msg2EmojiTranslator(
        tokenizer=tokenizer,
        generator=generator,
        device=device
    )
    
    return msg2emoji_translator

def text_preprocessing(text: str, ru_en_translator, zh_en_translator, language: str = 'en') -> str:
    if language == 'ru':
        text = ru_en_translator(text)
    elif language == 'zh':
        text = zh_en_translator(text)
    
    if len(text) > twitter_magic_number:
        print(f"It's twit translator. The max length of the input is {twitter_magic_number} characters")
        
    text_re = re.split(r"(?<=[.|!|?|\.\.\.])\s+", text.strip())
    
    return text_re

language_option = st.selectbox(
    "Select language:",
    available_languages.keys(),
    index=0,
    placeholder="Select language...",
)

text_value = st.text_area(
    label=language_label[language_option],
    placeholder=language_placeholder[language_option],
    max_chars=twitter_magic_number,
    help=f"Let's speak the language of facts üòâ. Facts are limited to {twitter_magic_number} chars (twit size)",
    height=150
)

ru_en_translator = load_ru_en_translator()
zh_en_translator = load_zh_en_translator()
msg2emoji_translator = load_msg2emoji_translator()

if st.button("Translate"):
    if not text_value:
        st.warning("Please, enter the message ü§î", icon="‚ö†Ô∏è")
    else:
        emoji_text = msg2emoji_translator.translate(
            text_preprocessing(text_value, ru_en_translator=ru_en_translator, zh_en_translator=zh_en_translator, language=language_abbr[language_option]),
            sep='',
            num_beams=5, 
            do_sample=True, 
            max_length=20
        )
        st.text_area(
            label="Emoji language",
            placeholder="Translated texts will appear here.",
            disabled=True,
            value=emoji_text,
        )
