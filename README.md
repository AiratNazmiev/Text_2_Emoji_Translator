## Модель для перевода коротких текстовых сообщений в эмодзи

Модель сделана на основе BART-base модели, дообученной на парах текст-набор эмодзи, взятых из открытых источников и сгенерированных с помощью LLM (Chat-GPT и DeepSeek). 
BART-base (Bidirectional and Auto-Regressive Transformers) — это трансформерная модель от Meta, предназначенная  для обработки естественного языка. Она объединяет идеи BERT (двунаправленного кодировщика) и GPT (авторегрессионного декодера) в архитектуре encoder–decoder, аналогичной трансформеру.
Упор в обучении был полностью сделан на английский язык. Запросы, кроме английского, доступны на руссклм и китайском. Для этого введенный пользователем текст предварительно переводится с ипользованием модели Helsinki-NLP/opus-mt-ru-en и Helsinki-NLP/opus-mt-zh-en.
Переводчики также имеют BART-подобную архитекуру, специализированную на машинном переводе (MarianMT, обученная на OPUS). 
